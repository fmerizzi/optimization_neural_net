 # Neural network project 
Simple neural network implementation, based on MNIST example.
net.py contains all the necessary functions. 
Basic functionalities: 

1) compute SGD on training data 
2) Run backprop algorithm, obtain gradient values of the network 
3) update weight and biases 
4) using basic sigmoid function neurons 
5) Produce animation of bias and weight updates during epochs 

## Backprop algorithm visualization 

![backprop](https://user-images.githubusercontent.com/32902835/110661686-1c673b80-81c5-11eb-8117-ff8f0a7c6c7d.png)
